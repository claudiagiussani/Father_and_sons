{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I LEGISLATURA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import time\n",
    "import pprint\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,precision_recall_curve, average_precision_score, confusion_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import pandas\n",
    "import operator\n",
    "from functools import reduce\n",
    "import editdistance\n",
    "import copy\n",
    "import regex\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "1. Import dataset\n",
    "2. Pulizia\n",
    "3. Index - seduta\n",
    "4. Interrogazioni\n",
    "5. Presidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = 'parliament/I_legislature_italian_republic.json'\n",
    "\n",
    "with open(dataset_file, 'r') as infile:\n",
    "    dataset = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.camera.it/_dati/leg01/lavori/stenografici/sed0100/sed0100.pdf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[it:0.9999977778254913]\n"
     ]
    }
   ],
   "source": [
    "pprint(detect_langs(dataset[0]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi e controlli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studio lunghezza limite\n",
    "Studio la lunghezza media dell'introduzione a ciascuna pagina in modo da impostare una thershold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = []\n",
    "intro = ['Atti ', 'Alti ', 'A t t i ', 'Att i ', 'Alt i ', 'Allt ', 'At t i ', 'd t t i ']\n",
    "\n",
    "for d in dataset:\n",
    "    d['text'] = d['text'].replace('\\n', '')\n",
    "    year = d['date'].split('-')[0][1:4] #uso 948 perchè spesso c'è i948\n",
    "    \n",
    "    resulttot = []\n",
    "    for i in intro:\n",
    "        result = re.findall(i+'(.+?)'+year, d['text'])\n",
    "        result = [i+elem+year for elem in result]\n",
    "        \n",
    "        resulttot.append(result)\n",
    "\n",
    "    resulttot = reduce(operator.concat, resulttot)\n",
    "\n",
    "    find.append(resulttot)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = reduce(operator.concat, find)\n",
    "\n",
    "lenght = []\n",
    "for l in find:\n",
    "    if len(l)<4000:\n",
    "        lenght.append(len(l))\n",
    "    if len(l)>160:\n",
    "        pprint(l)\n",
    "\n",
    "plt.boxplot(lenght, vert=False)\n",
    "#metto 160 come limite massimo, sopra quella soglia non considero la regex e non taglio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voglio vedere quante volte riesco a trovare la dicitura che mi indica l'inizio della seduta\n",
    "\n",
    "result = []  #lento, con search e non findall molto più veloce (tanto mi serve solo la prima volta di inizio seduta)\n",
    "for d in dataset:\n",
    "        res = regex.search('(La){e<2}\\s+(seduta){e<3}\\s+(comincia){e<4}',d['text'])\n",
    "        if res != None:\n",
    "            result.append(res.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103\n",
      "1113\n"
     ]
    }
   ],
   "source": [
    "pprint(len(result))\n",
    "pprint(len(dataset))\n",
    "\n",
    "#ho una buona approssimazione, quasi il 100% dei testi vengono divisi\n",
    "#capita che ne trovi due ma cmq eseguo lo split solo alla prima posizione, uso quindi regex.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerco quante volte riesco a trovare l'inizio delle interrogazioni\n",
    "\n",
    "notresult = []\n",
    "result = []\n",
    "cont = 0\n",
    "\n",
    "for d in dataset_pulito:\n",
    "    if 'seduta' in d.keys():\n",
    "        res = regex.search('(Si){e<2}\\s+(dia){e<2}\\s+(lettura){e<3}\\s+(delle){e<2}\\s+(interrogazioni){e<6}',d['seduta'])\n",
    "        if res != None:\n",
    "            result.append(res.group())\n",
    "        else: notresult.append(cont)\n",
    "    cont = cont + 1\n",
    "\n",
    "#lo trovo solo 380 volte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n"
     ]
    }
   ],
   "source": [
    "pprint(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voglio vedere quante volte riesco a trovare la dicitura che indica il presidente\n",
    "\n",
    "result = []\n",
    "\n",
    "for d in dataset_pulito:\n",
    "    if 'index' in d.keys():\n",
    "        res = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(PRESIDENTE){e<4}',d['index']) \n",
    "        \n",
    "        if res != None:\n",
    "            result.append(res.group())\n",
    "        else:    \n",
    "            res = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(VICEPRESIDENTE){e<4}',d['index']) \n",
    "\n",
    "            if res != None:\n",
    "                result.append(res.group())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063\n"
     ]
    }
   ],
   "source": [
    "pprint(len(result))\n",
    "#95% delle volte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulizia del testo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prima pulizia\n",
    "Rimonzione \\n e introduzione di ogni pagina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pulito = []\n",
    "find = []\n",
    "intro = ['Atti ', 'Alti ', 'A t t i ', 'Att i ', 'Alt i ', 'Allt ', 'At t i ', 'd t t i ']\n",
    "\n",
    "for d in dataset:\n",
    "    d['text'] = d['text'].replace('\\n', ' ')\n",
    "    year = d['date'].split('-')[0][1:4] #uso 948 perchè spesso c'è i948\n",
    "    \n",
    "    resulttot = []\n",
    "    for i in intro:\n",
    "        result = re.findall(i+'(.+?)'+year, d['text'])\n",
    "        result = [i+elem+year for elem in result]\n",
    "        result = [elem for elem in result if len(elem)< 160]\n",
    "        \n",
    "        resulttot.append(result)\n",
    "\n",
    "    resulttot = reduce(operator.concat, resulttot)\n",
    "    #pprint(resulttot)\n",
    "    find.append(resulttot)\n",
    "    \n",
    "    for l in resulttot:\n",
    "        d['text'] = d['text'].replace(l, '')\n",
    "        \n",
    "    dataset_pulito.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dataset_pulito[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Inizio e fine seduta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divido il text in index (parte prima dell'inizio della seduta) e seduta\n",
    "\n",
    "for d in dataset_pulito:\n",
    "    res = regex.search('(La){e<2}\\s+(seduta){e<3}\\s+(comincia){e<4}',d['text'])\n",
    "    if res !=None:\n",
    "        split = d['text'].split(res.group(),1)\n",
    "        d.pop('text', None)\n",
    "        d['index'],d['seduta'] = split[0], split[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "#verifico quanti documenti non sono stati splittati in index e seduta\n",
    "\n",
    "cont = 0\n",
    "for d in dataset_pulito:\n",
    "    if 'index' not in d.keys():\n",
    "        cont+=1\n",
    "        \n",
    "pprint(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitto la fine della seduta\n",
    "\n",
    "for d in dataset_pulito:\n",
    "    if 'seduta' in d.keys():\n",
    "        res = regex.search('(La){e<2}\\s+(seduta){e<2}\\s+(termina){e<3}',d['seduta'])\n",
    "        if res !=None:\n",
    "            split = d['seduta'].split(res.group(),1)\n",
    "            d['seduta'],d['end'] = split[0], split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n"
     ]
    }
   ],
   "source": [
    "#verifico quanti documenti non sono stati splittati in seduta e end\n",
    "\n",
    "cont = 0\n",
    "for d in dataset_pulito:\n",
    "    if 'end' not in d.keys():\n",
    "        cont+=1\n",
    "        \n",
    "pprint(cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Interrogazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitto e creo il campo interrogazioni\n",
    "\n",
    "for d in dataset_pulito:\n",
    "    if 'seduta' in d.keys():\n",
    "        res = regex.search('(Si){e<2}\\s+(dia){e<2}\\s+(lettura){e<3}\\s+(delle){e<2}\\s+(interrogazioni){e<6}',d['seduta'])\n",
    "        if res !=None:\n",
    "            split = d['seduta'].split(res.group())\n",
    "            d['seduta'], d['inter'] = split[0], split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n"
     ]
    }
   ],
   "source": [
    "#verifico quanti documenti non sono stati splittati in seduta e interrogazioni\n",
    "\n",
    "cont = 0\n",
    "for d in dataset_pulito:\n",
    "    if 'interrogazioni' not in d.keys():\n",
    "        cont+=1\n",
    "        \n",
    "pprint(cont) #non dovrei trovarle in quanto sono già state messe in end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trovare presidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '\\w+|\\$[\\d\\.]+|\\S+'\n",
    "tokenizer = RegexpTokenizer(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_presidente(data):\n",
    "        pres = {}\n",
    "        res = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(PRESIDENTE){e<4}',data) \n",
    "        \n",
    "        if res != None:\n",
    "            pres['presidente'] = data.split(res.group())[1]\n",
    "            pres['presidente'] = tokenizer.tokenize(pres['presidente'])\n",
    "            pres['presidente'] = [x for x in pres['presidente'] if x not in punctuation]\n",
    "            return pres\n",
    "        \n",
    "        elif regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(VICEPRESIDENTE){e<6}',data) != None: \n",
    "            res = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(VICEPRESIDENTE){e<6}',data)\n",
    "            pres['presidente'] = data.split(res.group())[1]\n",
    "            pres['presidente'] = tokenizer.tokenize(pres['presidente'])\n",
    "            pres['presidente'] = [x for x in pres['presidente'] if x not in punctuation]\n",
    "            return pres\n",
    "        \n",
    "        elif regex.search('(P R E S I D E N Z A D E L V I C E P R E S I D E N T E) {e<5}',data) != None:\n",
    "            res = regex.search('(P R E S I D E N Z A D E L V I C E P R E S I D E N T E) {e<5}',data)\n",
    "            pres['presidente'] = data.split(res.group())[1]\n",
    "            pres['presidente'] = tokenizer.tokenize(pres['presidente'])\n",
    "            pres['presidente'] = [x for x in pres['presidente'] if x not in punctuation]\n",
    "            return pres\n",
    "        \n",
    "        elif regex.search('(P R E S I D E N Z A D E L P R E S I D E N T E) {e<5}',data) != None:\n",
    "            res = regex.search('(P R E S I D E N Z A D E L P R E S I D E N T E) {e<5}',data)\n",
    "            pres['presidente'] = data.split(res.group())[1]\n",
    "            pres['presidente'] = tokenizer.tokenize(pres['presidente'])\n",
    "            pres['presidente'] = [x for x in pres['presidente'] if x not in punctuation]\n",
    "            return pres\n",
    "        \n",
    "        else: return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vado a salvare il campo presidente\n",
    "#In questa legis la maggior parte delle volte il presidente ha solo il cognome\n",
    "\n",
    "presidenza = []\n",
    "result = []\n",
    "cont = 0\n",
    "\n",
    "for d in dataset_pulito:\n",
    "    if 'index' in d.keys():\n",
    "        check = False\n",
    "        pres = find_presidente(d['index'])\n",
    "        \n",
    "        if pres!= False:\n",
    "            if regex.search('(PROVVISORIO){e<4}',pres['presidente'][0]) != None :\n",
    "                    check = True\n",
    "\n",
    "            if check == True:\n",
    "                if pres['presidente'][2].isupper() and len(pres['presidente'][2])>1 and pres['presidente'][2][0:4]!= 'INDI':\n",
    "                    pres['presidente'] = pres['presidente'][1]+\" \"+pres['presidente'][2]\n",
    "                     \n",
    "                    if pres['presidente'].split(' ')[1] == 'DEL' or pres['presidente'].split(' ')[1] == 'PAG':\n",
    "                        pres['presidente'] = pres['presidente'].split(' ')[0]\n",
    "\n",
    "                else:  \n",
    "                    pres['presidente'] = pres['presidente'][1]\n",
    "\n",
    "            else:\n",
    "                if pres['presidente'][1].isupper() and len(pres['presidente'][1])>1 and pres['presidente'][1][0:4]!= 'INDI':\n",
    "                    pres['presidente'] = pres['presidente'][0]+\" \"+pres['presidente'][1]\n",
    "                    \n",
    "                    if pres['presidente'].split(' ')[1] == 'DEL' or pres['presidente'].split(' ')[1] == 'PAG':\n",
    "                        pres['presidente'] = pres['presidente'].split(' ')[0]\n",
    "                        \n",
    "                else:   pres['presidente'] = pres['presidente'][0]\n",
    "\n",
    "\n",
    "            d['presidente'] = [pres['presidente']]  #salvo tutto come presidente, non tengo la distinzione\n",
    "\n",
    "    else:\n",
    "        pres = {}\n",
    "        pres['presidente'] = []\n",
    "   \n",
    "    if pres!= False:    \n",
    "        pres['doc'] = cont\n",
    "\n",
    "    presidenza.append(pres)\n",
    "    cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(presidenza)\n",
    "#GRONCHI - MARTINO - LEONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( dataset_pulito, open(\"Dataset_pulito.nosync/dataset_pulito_I_prima.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pulito = pickle.load( open( \"Dataset_pulito.nosync/dataset_pulito_I_prima.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for d in dataset_pulito:\n",
    "    if 'presidente' in d.keys():\n",
    "        cont = cont+1\n",
    "        \n",
    "pprint(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "pres = {}\n",
    "\n",
    "for d in dataset_pulito: \n",
    "    if 'seduta' in d.keys() and 'presidente' in d.keys():\n",
    "        d['seduta'] = [d['seduta']]\n",
    "        i = 0\n",
    "        res = None\n",
    "        \n",
    "        r = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(PRESIDENTE){e<6}',d['seduta'][0])\n",
    "        if r!= None:\n",
    "            res = r\n",
    "\n",
    "        r = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(VICEPRESIDENTE){e<6}',d['seduta'][0])\n",
    "        if r != None and res!= None and r.span()[0]<res.span()[0]:\n",
    "            res = r\n",
    "\n",
    "        r = regex.search('(P R E S I D E N Z A D E L V I C E P R E S I D E N T E) {e<5}',d['seduta'][0])\n",
    "        if r != None and res!= None and r.span()[0]<res.span()[0]:\n",
    "            res = r    \n",
    "            \n",
    "        r = regex.search('(P R E S I D E N Z A D E L P R E S I D E N T E) {e<5}',d['seduta'][0])\n",
    "        if r != None and res!= None and r.span()[0]<res.span()[0]:\n",
    "            res = r \n",
    "\n",
    "        while res != None: #continuo a splittare finchè trovo che c'è un nuovo presidente\n",
    "            check = False\n",
    "            split = d['seduta'][i].split(res.group(),1)\n",
    "            d['seduta'].pop(i)\n",
    "            d['seduta'].append(split[0])\n",
    "            d['seduta'].append(split[1])\n",
    "\n",
    "            pres['presidente'] = tokenizer.tokenize(split[1])\n",
    "            pres['presidente'] = [x for x in pres['presidente'] if x not in punctuation]\n",
    "\n",
    "            if regex.search('(PROVVISORIO){e<4}',pres['presidente'][0]) != None :\n",
    "                check = True\n",
    "                \n",
    "            if check == True:\n",
    "                pres['presidente'] = pres['presidente'][1]\n",
    "\n",
    "            else:\n",
    "                pres['presidente'] = pres['presidente'][0]\n",
    "\n",
    "            d['presidente'].append(pres['presidente'])\n",
    "            \n",
    "            i = i +1\n",
    "            \n",
    "            res = None\n",
    "\n",
    "            r = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(PRESIDENTE){e<6}',d['seduta'][i])\n",
    "            if r!= None:\n",
    "                res = r\n",
    "\n",
    "            r = regex.search('(PRESIDENZA){e<4}\\s+(DEL){e<3}\\s+(VICEPRESIDENTE){e<6}',d['seduta'][i])\n",
    "            if r != None and res!= None and r.span()[0]<res.span()[0]:\n",
    "                res = r\n",
    "\n",
    "            r = regex.search('(P R E S I D E N Z A D E L V I C E P R E S I D E N T E) {e<5}',d['seduta'][i])\n",
    "            if r != None and res!= None and r.span()[0]<res.span()[0]:\n",
    "                res = r    \n",
    "            \n",
    "            r = regex.search('(P R E S I D E N Z A D E L P R E S I D E N T E) {e<5}',d['seduta'][i])\n",
    "            if r != None and res!= None and r.span()[0]<res.span()[0]:\n",
    "                res = r \n",
    "            \n",
    "    pprint(cont)       \n",
    "    cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "res = []\n",
    "for d in dataset_pulito:\n",
    "    if 'presidente' in d.keys():\n",
    "        print(cont)\n",
    "        print(d['presidente'])\n",
    "        res.append(cont)\n",
    "        \n",
    "    cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.camera.it/_dati/leg01/lavori/stenografici/sed0099/sed0099.pdf'\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset_pulito[75]['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_p = []\n",
    "for d in dataset_pulito:\n",
    "    if 'presidente' in d.keys():\n",
    "        for p in d['presidente']:\n",
    "             len_p.append(len(d['presidente']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2.0519978106185004\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "pprint(np.max(len_p))\n",
    "pprint(np.mean(len_p))\n",
    "pprint(np.median(len_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( dataset_pulito, open(\"Dataset_pulito.nosync/dataset_pulito_I.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisione dei discorsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pulito = pickle.load( open( \"Dataset_pulito.nosync/dataset_pulito_I.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "legis_I_leaders = {'DC': [('Aldo', 'Moro'), ('Oscar Luigi', 'Scalfaro'), ('Alcide', 'De Gasperi'), ('Amintore', 'Fanfani'), \n",
    "                          ('Giovanni', 'Gronchi'), ('Antonio', 'Segni'), ('Giovanni', 'Leone'), ('Mariano', 'Rumor'), \n",
    "                          ('Giulio', 'Andreotti')],\n",
    "'PCI': [('Palmiro', 'Togliatti'), ('Giorgio','Amendola'), ('Giuseppe', 'Di Vittorio'), ('Antonio', 'Giolitti'), ('Pietro', 'Ingrao'), \n",
    "        ('Nilde', 'Iotti'), ('Giancarlo', 'Pajetta'), ('Luigi', 'Longo')],\n",
    "'PSI': [('Pietro', 'Nenni'), ('Carlo', 'Matteotti'), ('Lelio', 'Basso'), ('Giacomo','Mancini'), ('Francesco', 'De Martino')],\n",
    "'PSDI': [('Piero', 'Calamandrei'), ('Giuseppe', 'Saragat')],\n",
    "'PLI': ('Gaetano', 'Martino'),\n",
    "'PRI': [('Ugo', 'La Malfa'), ('Randolfo','Pacciardi')],\n",
    "'MISTO' : [('Giorgio', 'Almirante'), ('Guido', 'Russo Perez')],\n",
    "'MONARCHICO': ('Alfredo', 'Covelli')}\n",
    "\n",
    "politici_max_def_name = []\n",
    "\n",
    "for k in legis_I_leaders.keys():\n",
    "    if type(legis_I_leaders[k]) == list:\n",
    "        for t in legis_I_leaders[k]:\n",
    "            if t[1] == 'Pajetta':\n",
    "                politici_max_def_name.append(t[1].upper()+\" \"+t[0].upper())\n",
    "            else:\n",
    "                politici_max_def_name.append(t[1].upper())\n",
    "    else: politici_max_def_name.append(legis_I_leaders[k][1].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(politici_max_def_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "politici = {}\n",
    "\n",
    "for d in dataset_pulito:\n",
    "    if 'presidente' in d.keys():\n",
    "        for p in d['presidente']:\n",
    "            if p not in politici.keys():\n",
    "                politici[p] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(politici)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cont = 0\n",
    "flag = 0\n",
    "\n",
    "for data in dataset_pulito:\n",
    "    if 'seduta' in data.keys() and 'presidente' in data.keys():\n",
    "        for k in range(0,len(data['seduta'])):\n",
    "            presidente = data['presidente'][k]\n",
    "            \n",
    "            text = data['seduta'][k]\n",
    "            text_token = tokenizer.tokenize(text)\n",
    "            text_token = [x for x in text_token if x not in punctuation]\n",
    "\n",
    "            for i in range(0,len(text_token)):\n",
    "\n",
    "                    word = text_token[i]\n",
    "                    politico = re.search(r\"[A-Z]{2,}\", word)\n",
    "\n",
    "                    if politico != None and i+2<len(text_token):\n",
    "                        if editdistance.eval(politico.group(), 'PRESIDENTE')<4:\n",
    "                            pol = presidente\n",
    "                            politici[pol] = politici[pol]+1\n",
    "                        \n",
    "                        else:\n",
    "                            if flag == 0: \n",
    "                                flag = 0\n",
    "                                if text_token[i+1].isupper() and len(text_token[i+1])>1 and text_token[i+1][0]!='(' : #ignoro cose tipo XIII legisl\n",
    "\n",
    "                                    if text_token[i+2].isupper() and len(text_token[i+2])>2 and text_token[i+2][0]!='(':\n",
    "                                        pol = word+\" \"+text_token[i+1]+\" \"+text_token[i+2]\n",
    "\n",
    "                                        if pol not in politici.keys():\n",
    "                                            politici[pol] = 1\n",
    "                                        else: politici[pol] = politici[pol]+1\n",
    "                                        flag = 2\n",
    "\n",
    "\n",
    "                                    else:\n",
    "                                        pol = word+\" \"+text_token[i+1]\n",
    "                                        if pol not in politici.keys():\n",
    "                                            politici[pol] = 1\n",
    "                                        else: politici[pol] = politici[pol]+1\n",
    "                                        flag = 1\n",
    "                                    \n",
    "                                else:\n",
    "                                    pol = word\n",
    "                                    if pol not in politici.keys():\n",
    "                                            politici[pol] = 1\n",
    "                                    else: politici[pol] = politici[pol]+1\n",
    "                                        \n",
    "                            else: flag = flag -1\n",
    "\n",
    "            cont = cont +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint((politici))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "politici_max = [] #tengo solamente quelli con almeno 5 occorrenze\n",
    "\n",
    "for k in politici.keys():\n",
    "    if politici[k] > 4:\n",
    "        politici_max.append([k, politici[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959\n"
     ]
    }
   ],
   "source": [
    "pprint(len(politici_max))\n",
    "#li considero come tutti i politici\n",
    "#lo uso per scartare quelli che non dovrebbero essere politici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "politici_max_name = [elem[0] for elem in politici_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#li aggrego in base alle somiglianze nel nome\n",
    "\n",
    "politici_definitivi = []\n",
    "cont = 1\n",
    "\n",
    "for p in politici_max:\n",
    "    for i in range(cont, len(politici_max)):\n",
    "        if len(p[0]) <=  10 and editdistance.eval(p[0],politici_max[i][0])<3:\n",
    "            p[1] = p[1] + politici_max[i][1]\n",
    "            politici_max[i][1] = 0\n",
    "        \n",
    "        if len(p[0]) > 10 and editdistance.eval(p[0],politici_max[i][0])<4:\n",
    "            p[1] = p[1] + politici_max[i][1]\n",
    "            politici_max[i][1] = 0\n",
    "            \n",
    "    cont = cont +1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimino quelli che sono stati aggregati\n",
    "politici_max_agg = [elem for elem in politici_max if elem[1]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(sorted(politici_max_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non ho bisono della soglia in quanto ho già i politici di interesse, capire cosa usare per decidere se è \n",
    "#un politico o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_politico(pol):\n",
    "    \n",
    "    if politico == 'SCOTTI': #Scotti crea problemi con IOTTI, lo ignoro in quanto non mi interessa\n",
    "        return False, None\n",
    "    \n",
    "    if politico == 'CAVALLI': #Cavalli crea problemi con Covelli\n",
    "        return False, None\n",
    "    \n",
    "    if politico == 'PAJETTA GIAN':\n",
    "        return True, 'PAJETTA GIANCARLO'\n",
    "        \n",
    "    for cog in politici_max_def_name:\n",
    "            res = editdistance.eval(cog,pol)\n",
    "            \n",
    "            if len(pol)<=5 and res <2:\n",
    "                return True, cog\n",
    "            \n",
    "            elif len(pol)  <= 10 and res<3: #così non posso fare de martino = martino\n",
    "                return True, cog\n",
    "                \n",
    "            elif len(pol) > 10 and res<5:\n",
    "                return True, cog\n",
    "    \n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "discorsi = {}\n",
    "\n",
    "for cog in politici_max_def_name:\n",
    "    discorsi[cog] = []\n",
    "    \n",
    "    #in questo caso ho solo cognomi corretti, ma con i confronti dovrei riuscire a recuperarne la maggior parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvo i discorsi\n",
    "\n",
    "cont = 0\n",
    "flag = 0\n",
    "d = {}\n",
    "\n",
    "\n",
    "for data in dataset_pulito:\n",
    "    if 'seduta' in data.keys() and 'presidente' in data.keys():\n",
    "         for k in range(0,len(data['seduta'])):\n",
    "            presidente = data['presidente'][k]\n",
    "            \n",
    "            text = data['seduta'][k]\n",
    "            text_token = tokenizer.tokenize(text)\n",
    "            text_token = [x for x in text_token if x not in punctuation]\n",
    "            i = 0\n",
    "            flag = 0\n",
    "            d = {}\n",
    "\n",
    "            for word in text_token:\n",
    "\n",
    "                    politico = re.search(r\"[A-Z]{2,}\", word) #2 perchè ho de martino e de gasperi\n",
    "\n",
    "                    if politico != None and i+2<len(text_token):\n",
    "                        \n",
    "                        if editdistance.eval(politico.group(), 'PRESIDENTE')<4:\n",
    "                            pprint(politico.group())\n",
    "                            \n",
    "                            if d!={} and len(d['discorso'])>2:\n",
    "                                discorsi[d['politico']].append(d['discorso'])\n",
    "                                pprint(str(cont)+' '+d['politico'])\n",
    "                            \n",
    "                                \n",
    "                            flag = 0\n",
    "                            d = {}\n",
    "                            \n",
    "                            pres, cog_pres = check_politico(presidente) #controllo se il presidente mi interessa\n",
    "                            \n",
    "                            if pres == True:\n",
    "                                d['politico'] = cog_pres\n",
    "                                d['discorso'] = []\n",
    "                                flag = 1\n",
    "                        \n",
    "                        else:\n",
    "                            pol = politico.group()\n",
    "      \n",
    "                            pol2 =  politico.group()+\" \"+text_token[i+1]\n",
    "                            \n",
    "                            if editdistance.eval('LEONE-MARCHESANO', word)<4:\n",
    "                                pol = word #la regex non riconosce -\n",
    "        \n",
    "                            if text_token[i+1] == '-':\n",
    "                                pol2 = politico.group()+\" \"+text_token[i+1]+\" \"+text_token[i+2]\n",
    "                            \n",
    "                            if (pol in politici_max_name) or (pol2 in politici_max_name): #se non è in questa lista non lo considero un politico \n",
    "                                    if d!={} and len(d['discorso'])>2: #salvo perchè significa che inizia un altro discorso\n",
    "                                        discorsi[d['politico']].append(d['discorso'])\n",
    "                                        pprint(str(cont)+' '+d['politico'])\n",
    "                                        \n",
    "                                    \n",
    "                                    flag = 0\n",
    "                                    d = {}\n",
    "                                    \n",
    "                                        \n",
    "\n",
    "                                    if (text_token[i+1].isupper() and len(text_token[i+1])>2) or text_token[i+1][0]=='-': \n",
    "                                        check, cog = check_politico(pol2)\n",
    "                                        if check == True:\n",
    "                                            d['politico'] = cog\n",
    "                                            d['discorso'] = []\n",
    "                                            text_token.pop(i+1)\n",
    "                                            \n",
    "                                            if text_token[i+1] == '-':\n",
    "                                                text_token.pop(i+1)\n",
    "                                            flag = 1\n",
    "                                            \n",
    "                                    elif editdistance.eval(word, 'PAJETTA')<3:\n",
    "                                        pol3 = politico.group()+\" \"+text_token[i+1]+\" \"+text_token[i+2]\n",
    "                                        check, cog = check_politico(pol3)\n",
    "                                        if check == True:\n",
    "                                            d['politico'] = cog\n",
    "                                            d['discorso'] = []\n",
    "                                            text_token.pop(i+1)\n",
    "                                            text_token.pop(i+1)\n",
    "                                            \n",
    "                                            flag = 1\n",
    "                                        \n",
    "\n",
    "                                    else:\n",
    "                                        check, cog = check_politico(pol)\n",
    "                                        if check == True:\n",
    "                                            flag = 1\n",
    "                                            d['politico'] = cog\n",
    "                                            d['discorso'] = []\n",
    "                                            \n",
    "\n",
    "                            elif flag == 1: #vuol dire che è una parola in maiuscolo ma non è un politico\n",
    "                                d['discorso'].append(word)\n",
    "                         \n",
    "                    elif flag ==1:\n",
    "                        d['discorso'].append(word)\n",
    "                    i = i +1\n",
    "                    \n",
    "            if d != {} and len(d['discorso'])>2: \n",
    "                discorsi[d['politico']].append(d['discorso'])\n",
    "                pprint(str(cont)+' '+d['politico'])\n",
    "               \n",
    "    cont = cont +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Com', \"'e\", 'il', 'lodo', 'De', 'Gasperi']\n"
     ]
    }
   ],
   "source": [
    "print(discorsi['DI VITTORIO'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.camera.it/_dati/leg01/lavori/stenografici/sed0013/sed0013.pdf'\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset_pulito[10]['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALMIRANTE 680\n",
      "AMENDOLA 24\n",
      "ANDREOTTI 225\n",
      "BASSO 413\n",
      "CALAMANDREI 97\n",
      "COVELLI 384\n",
      "DE GASPERI 563\n",
      "DE MARTINO 234\n",
      "DI VITTORIO 1456\n",
      "FANFANI 814\n",
      "GIOLITTI 883\n",
      "GRONCHI 16892\n",
      "INGRAO 57\n",
      "IOTTI 137\n",
      "LA MALFA 418\n",
      "LEONE 3917\n",
      "LONGO 93\n",
      "MANCINI 197\n",
      "MARTINO 4668\n",
      "MATTEOTTI 0\n",
      "MORO 1648\n",
      "NENNI 13\n",
      "PACCIARDI 415\n",
      "PAJETTA GIANCARLO 23\n",
      "RUMOR 105\n",
      "RUSSO PEREZ 582\n",
      "SARAGAT 202\n",
      "SCALFARO 242\n",
      "SEGNI 1331\n",
      "TOGLIATTI 350\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(discorsi.keys()):\n",
    "    print(k+\" \"+str(len(discorsi[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALMIRANTE 680\n",
      "AMENDOLA 24\n",
      "ANDREOTTI 225\n",
      "BASSO 413\n",
      "CALAMANDREI 97\n",
      "COVELLI 384\n",
      "DE GASPERI 563\n",
      "DE MARTINO 234\n",
      "DI VITTORIO 1456\n",
      "FANFANI 814\n",
      "GIOLITTI 883\n",
      "GRONCHI 16892\n",
      "INGRAO 57\n",
      "IOTTI 137\n",
      "LA MALFA 418\n",
      "LEONE 3917\n",
      "LONGO 93\n",
      "MANCINI 197\n",
      "MARTINO 4668\n",
      "MATTEOTTI 0\n",
      "MORO 1648\n",
      "NENNI 13\n",
      "PACCIARDI 415\n",
      "PAJETTA GIANCARLO 5\n",
      "RUMOR 105\n",
      "RUSSO PEREZ 582\n",
      "SARAGAT 202\n",
      "SCALFARO 242\n",
      "SEGNI 1331\n",
      "TOGLIATTI 350\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(discorsi.keys()):\n",
    "    print(k+\" \"+str(len(discorsi[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dataset_pulito[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng = []\n",
    "\n",
    "for k in discorsi.keys():\n",
    "    if k!= 'GRONCHI':\n",
    "        leng.append(len(discorsi[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1648, 242, 563, 814, 1331, 3917, 105, 225, 350, 24, 1456, 883, 57, 137, 5, 93, 13, 0, 413, 197, 234, 97, 202, 4668, 418, 415, 680, 582, 384]\n",
      "694.9310344827586\n"
     ]
    }
   ],
   "source": [
    "print(leng)\n",
    "print(np.mean(leng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvo un file per ciascun politico con i suoi discorso\n",
    "\n",
    "for cog in discorsi.keys():\n",
    "    pickle.dump( discorsi[cog], open( 'Discorsi-I-legis/'+cog+\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( list(discorsi.keys()), open( 'Discorsi-I-legis/cognomi_discorsi.p', \"wb\" ) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto della situazione\n",
    "#### Cose fatte:\n",
    "1. Rimosso intestazione\n",
    "2. Trovato \"la seduta comincia\" e splittato in index e seduta\n",
    "3. Trovato il presidente\n",
    "4. Trovato \"Si dia lettura delle interrogazioni\" e splittato in seduta e inter\n",
    "5. Salvato tutto come dataset_pulito\n",
    "6. Rimosso la punteggiatura e identificati i politici e relativi discorsi\n",
    "7. Salvato tutto in un file per ciascun politico\n",
    " \n",
    "                                                \n",
    "30 politici di interesse - 1234 discorsi in media (694 senza Gronchi) con mediana 367 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
