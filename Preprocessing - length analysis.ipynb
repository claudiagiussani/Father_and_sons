{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepocessing and lenght Analysis\n",
    "Analisi della lunghezza dei discorsi per decidere i politici da utilizzare per l'analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import time\n",
    "import pprint\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import pandas\n",
    "import operator\n",
    "from functools import reduce\n",
    "import editdistance\n",
    "import copy\n",
    "import regex\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import textrazor\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "stopwords = set(stopwords.words('italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cognomi = {}\n",
    "cognomi['I'] = pickle.load( open( \"Discorsi-I-legis/cognomi_discorsi.p\", \"rb\" ) )\n",
    "cognomi['XII'] = pickle.load( open( \"Discorsi-XII-legis/cognomi_discorsi.p\", \"rb\" ) )\n",
    "cognomi['XVII'] = pickle.load( open( \"Discorsi-XVII-legis/cognomi_discorsi.p\", \"rb\" ) )\n",
    "cognomi['XVIII'] = pickle.load( open( \"Discorsi-XVIII-legis/cognomi_discorsi.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "legis = {l:{} for l in cognomi.keys()}\n",
    "for l in legis.keys():\n",
    "    legis[l] = {cog: pickle.load( open( \"Discorsi-\"+l+\"-legis/\"+cog+\".p\", \"rb\" ) ) for cog in cognomi[l]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 30\n",
      "XII 80\n",
      "XVII 175\n",
      "XVIII 108\n"
     ]
    }
   ],
   "source": [
    "# numero di discorsi\n",
    "for l in legis.keys():\n",
    "    print(l+\" \"+str(len(legis[l])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1648"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(legis['I']['MORO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30+80+175+108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media numero di discorsi prima del preprocessing\n",
    "n_disco = {l:[] for l in legis}\n",
    "for l in legis:\n",
    "    n_disco[l] = [len(legis[l][cog]) for cog in legis[l].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 1235.4333333333334\n",
      "I 367.0\n",
      "XII 351.9\n",
      "XII 109.5\n",
      "XVII 559.0\n",
      "XVII 179.0\n",
      "XVIII 300.3425925925926\n",
      "XVIII 83.0\n"
     ]
    }
   ],
   "source": [
    "for l in n_disco:\n",
    "    print(l+\" \"+str(np.mean(n_disco[l])))\n",
    "    print(l+\" \"+str(np.median(n_disco[l])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvataggio discorsi puliti ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = lambda text: [x.lemma_ for x in nlp(text) if x.pos_ not in ['PUNCT', 'SPACE'] and not x.is_stop]\n",
    "#all_tokens = lambda text: [x.lemma_ for x in nlp(text) if x.pos_ not in ['PUNCT', 'SPACE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = ' '\n",
    "cont = 0\n",
    "leg = 'I'\n",
    "for cog in legis[leg].keys():\n",
    "    if legis[leg][cog]!= []:\n",
    "        cont = 0\n",
    "        for l in legis[leg][cog]:\n",
    "            l = legis[leg][cog][cont]         \n",
    "            l = separator.join(l).lower()\n",
    "            l = tokens(l)\n",
    "            l = list(l)\n",
    "            legis[leg][cog][cont] = l\n",
    "            cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cog in legis[leg].keys():\n",
    "    pickle.dump( legis[leg][cog], open( 'Discorsi_puliti_I/'+cog+\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = ' '\n",
    "cont = 0\n",
    "leg = 'XVII'\n",
    "for cog in legis[leg].keys():\n",
    "    if legis[leg][cog]!= []:\n",
    "        cont = 0\n",
    "        for l in legis[leg][cog]:\n",
    "            l = legis[leg][cog][cont]         \n",
    "            l = separator.join(l).lower()\n",
    "            l = tokens(l)\n",
    "            l = list(l)\n",
    "            legis[leg][cog][cont] = l\n",
    "            cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cog in legis[leg].keys():\n",
    "    pickle.dump( legis[leg][cog], open( 'Discorsi_puliti_XVII/'+cog+\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = ' '\n",
    "cont = 0\n",
    "leg = 'XII'\n",
    "for cog in legis[leg].keys():\n",
    "    if legis[leg][cog]!= []:\n",
    "        cont = 0\n",
    "        for l in legis[leg][cog]:\n",
    "            l = legis[leg][cog][cont]         \n",
    "            l = separator.join(l).lower()\n",
    "            l = tokens(l)\n",
    "            l = list(l)\n",
    "            legis[leg][cog][cont] = l\n",
    "            cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cog in legis[leg].keys():\n",
    "    pickle.dump( legis[leg][cog], open( 'Discorsi_puliti_XII/'+cog+\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XVIII legis in quanto ha i nomi dei partiti a inizio frase\n",
    "leg = 'XVIII'\n",
    "separator = ' '\n",
    "cont = 0\n",
    "for cog in legis[leg].keys():\n",
    "    if legis[leg][cog]!= []:\n",
    "        cont = 0\n",
    "        for l in legis[leg][cog]:\n",
    "            if l!= [] and l[0][0] == '(' and len(l[0])<15: #rimuovo i nomi dei partiti prima degli interventi\n",
    "                    pprint(l[0])\n",
    "                    legis[leg][cog][cont].remove(l[0])\n",
    "            l = legis[leg][cog][cont]         \n",
    "            l = separator.join(l).lower()\n",
    "            l = tokens(l)\n",
    "            l = list(l)\n",
    "            legis[leg][cog][cont] = l\n",
    "            cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cog in legis[leg].keys():\n",
    "    pickle.dump( legis[leg][cog], open( 'Discorsi_puliti_XVIII/'+cog+\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro\n",
    "Per avere un dataset bilanciato e per problemi dovuti all'uso di TextRazor (max 500 discorsi), decido di prendere random 1000 discorsi per politico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_legis = {}\n",
    "all_legis['I'] = {}\n",
    "all_legis['XII'] = {}\n",
    "all_legis['XVII'] = {} \n",
    "all_legis['XVIII'] =  {}\n",
    "\n",
    "for cog in cognomi['I']:\n",
    "    all_legis['I'][cog] = pickle.load( open( 'Discorsi_puliti_I/'+cog+\".p\", \"rb\" ) )\n",
    "    \n",
    "for cog in cognomi['XII']:\n",
    "    all_legis['XII'][cog] = pickle.load( open( 'Discorsi_puliti_XII/'+cog+\".p\", \"rb\" ) )\n",
    "    \n",
    "for cog in cognomi['XVIII']:\n",
    "    all_legis['XVIII'][cog] = pickle.load( open( 'Discorsi_puliti_XVIII/'+cog+\".p\", \"rb\" ) )\n",
    "    \n",
    "for cog in cognomi['XVII']:\n",
    "    all_legis['XVII'][cog] = pickle.load( open( 'Discorsi_puliti_XVII/'+cog+\".p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "MORO 1648\n",
      "DE GASPERI 563\n",
      "FANFANI 814\n",
      "GRONCHI 16892\n",
      "SEGNI 1331\n",
      "LEONE 3917\n",
      "TOGLIATTI 350\n",
      "DI VITTORIO 1456\n",
      "GIOLITTI 883\n",
      "BASSO 413\n",
      "MARTINO 4668\n",
      "LA MALFA 418\n",
      "PACCIARDI 415\n",
      "ALMIRANTE 680\n",
      "RUSSO PEREZ 582\n",
      "COVELLI 384\n",
      "XII\n",
      "IRENE PIVETTI 3141\n",
      "LUCIANO VIOLANTE 5907\n",
      "VITTORIO DOTTI 849\n",
      "IGNAZIO LA RUSSA 2483\n",
      "LORENZO ACQUARONE 3274\n",
      "RAFFAELE DELLA \\ALLE 3243\n",
      "FRANCESCO STORACE 404\n",
      "XVII\n",
      "LAURA BOLDRINI 12302\n",
      "ROBERTO GIACHETTI 15421\n",
      "MARINA SERENI 11318\n",
      "LUIGI DI MAIO 9666\n",
      "SIMONE BALDELLI 10412\n",
      "RESOCONTO STENOGRAFICO 663\n",
      "IGNAZIO LA RUSSA 768\n",
      "ROCCO BUTTIGLIONE 439\n",
      "NICOLA MOLTENI 557\n",
      "EMANUELE FIANO 493\n",
      "GIANLUCA PINI 489\n",
      "ARTURO SCOTTO 351\n",
      "DAVIDE CAPARINI 328\n",
      "FABIO RAMPELLI 363\n",
      "DANILO TONINELLI 444\n",
      "EDMONDO CIRIELLI 337\n",
      "GIAN LUIGI GIGLI 413\n",
      "MATTEO BRAGANTINI 389\n",
      "PAOLA BINETTI 395\n",
      "ETTORE ROSATO 388\n",
      "CARLO SIBILIA 432\n",
      "MASSIMILIANO FEDRIGA 650\n",
      "ROCCO PALESE 754\n",
      "STEFANO ALLASIA 329\n",
      "VITTORIO FERRARESI 413\n",
      "STEFANO QUARANTA 408\n",
      "ARCANGELO SANNICANDRO 619\n",
      "CRISTIAN INVERNIZZI 323\n",
      "FRANCESCO PAOLO SISTO 716\n",
      "ANDREA COLLETTI 582\n",
      "ALESSANDRO DI BATTISTA 306\n",
      "GIANLUCA BUONANNO 540\n",
      "ALFONSO BONAFEDE 391\n",
      "LUIGI GALLO 467\n",
      "COSIMO MARIA FERRI 330\n",
      "DAVIDE CRIPPA 841\n",
      "WALTER RIZZETTO 333\n",
      "GIANNI MELILLA 323\n",
      "ROBERTO SIMONETTI 375\n",
      "XVIII\n",
      "ROBERTO FICO 5296\n",
      "MARIA ROSARIA CARFAGNA 3860\n",
      "MARIA EDERA SPADONI 3240\n",
      "ETTORE ROSATO 4667\n",
      "FABIO RAMPELLI 4157\n",
      "FEDERICO FORNARO 420\n",
      "FRANCESCO PAOLO SISTO 301\n",
      "RENATA POLVERINI 345\n",
      "SIMONE BALDELLI 352\n",
      "ENRICO BORGHI 445\n",
      "EMANUELE FIANO 499\n"
     ]
    }
   ],
   "source": [
    "for l in all_legis:\n",
    "    print(l)\n",
    "    for cog in all_legis[l]:\n",
    "        if len(all_legis[l][cog])>300:\n",
    "            print(cog+\" \"+str(len(all_legis[l][cog])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rimuovo i discorsi composti da meno di 10 parole\n",
    "discorsi_ridotti = {l: {} for l in all_legis.keys()}\n",
    "\n",
    "for l in all_legis.keys():\n",
    "    for cog in all_legis[l].keys():\n",
    "        discorsi_ridotti[l][cog] = [d for d in all_legis[l][cog] if len(d)>10]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "MORO 1452\n",
      "DE GASPERI 373\n",
      "FANFANI 512\n",
      "GRONCHI 9138\n",
      "SEGNI 860\n",
      "LEONE 2204\n",
      "DI VITTORIO 688\n",
      "GIOLITTI 622\n",
      "BASSO 332\n",
      "MARTINO 2711\n",
      "ALMIRANTE 480\n",
      "XII\n",
      "IRENE PIVETTI 1537\n",
      "LUCIANO VIOLANTE 3420\n",
      "VITTORIO DOTTI 494\n",
      "IGNAZIO LA RUSSA 1456\n",
      "LORENZO ACQUARONE 1921\n",
      "RAFFAELE DELLA \\ALLE 1823\n",
      "XVII\n",
      "LAURA BOLDRINI 4387\n",
      "ROBERTO GIACHETTI 8347\n",
      "MARINA SERENI 5297\n",
      "LUIGI DI MAIO 4485\n",
      "SIMONE BALDELLI 5871\n",
      "RESOCONTO STENOGRAFICO 578\n",
      "ROCCO BUTTIGLIONE 364\n",
      "NICOLA MOLTENI 413\n",
      "GIANLUCA PINI 353\n",
      "FABIO RAMPELLI 304\n",
      "PAOLA BINETTI 364\n",
      "MASSIMILIANO FEDRIGA 415\n",
      "ROCCO PALESE 587\n",
      "ARCANGELO SANNICANDRO 470\n",
      "FRANCESCO PAOLO SISTO 536\n",
      "ANDREA COLLETTI 388\n",
      "ALFONSO BONAFEDE 305\n",
      "DAVIDE CRIPPA 491\n",
      "XVIII\n",
      "ROBERTO FICO 1810\n",
      "MARIA ROSARIA CARFAGNA 1852\n",
      "MARIA EDERA SPADONI 1409\n",
      "ETTORE ROSATO 2333\n",
      "FABIO RAMPELLI 2036\n",
      "FEDERICO FORNARO 332\n"
     ]
    }
   ],
   "source": [
    "leng = {}\n",
    "\n",
    "for l in discorsi_ridotti.keys():\n",
    "    print(l)\n",
    "    leng[l] = []\n",
    "    for cog in discorsi_ridotti[l]:\n",
    "        if len(discorsi_ridotti[l][cog]) > 300:\n",
    "            print(cog+\" \"+str(len(discorsi_ridotti[l][cog])))\n",
    "            leng[l].append((cog, len(discorsi_ridotti[l][cog])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in leng.keys():\n",
    "    leng[l] = sorted(leng[l], key=lambda tup: tup[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cognomi_analisi = {}\n",
    "cognomi_analisi['I'] = [leng['I'][i][0] for i in range(0,5)]\n",
    "cognomi_analisi['XII'] = [leng['XII'][i][0] for i in range(0,5)]\n",
    "cognomi_analisi['XVII'] = [leng['XVII'][i][0] for i in range(0,5)]\n",
    "cognomi_analisi['XVIII'] = [leng['XVIII'][i][0] for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': ['GRONCHI', 'MARTINO', 'LEONE', 'MORO', 'SEGNI'],\n",
       " 'XII': ['LUCIANO VIOLANTE',\n",
       "  'LORENZO ACQUARONE',\n",
       "  'RAFFAELE DELLA \\\\ALLE',\n",
       "  'IRENE PIVETTI',\n",
       "  'IGNAZIO LA RUSSA'],\n",
       " 'XVII': ['ROBERTO GIACHETTI',\n",
       "  'SIMONE BALDELLI',\n",
       "  'MARINA SERENI',\n",
       "  'LUIGI DI MAIO',\n",
       "  'LAURA BOLDRINI'],\n",
       " 'XVIII': ['ETTORE ROSATO',\n",
       "  'FABIO RAMPELLI',\n",
       "  'MARIA ROSARIA CARFAGNA',\n",
       "  'ROBERTO FICO',\n",
       "  'MARIA EDERA SPADONI']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognomi_analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cognomi_analisi, open( \"cognomi_analisi.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Salvataggio gruppi 1000 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "discorsi_analisi = {}\n",
    "for l in cognomi_analisi.keys():\n",
    "    discorsi_analisi[l] = {}\n",
    "    for cog in cognomi_analisi[l]:\n",
    "        if len(discorsi_ridotti[l][cog]) > 1000:\n",
    "            discorsi_analisi[l][cog] = []\n",
    "            pos = random.sample(range(0, len(discorsi_ridotti[l][cog])), 1000)\n",
    "            for p in pos:\n",
    "                discorsi_analisi[l][cog].append(discorsi_ridotti[l][cog][p])\n",
    "        else:\n",
    "            discorsi_analisi[l][cog] = discorsi_ridotti[l][cog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in discorsi_analisi.keys():\n",
    "    pickle.dump(discorsi_analisi[l], open( l+\"_discorsi_analisi.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long discorsi analisi ###\n",
    "Salvo per ogni legis i primi 2 politici aventi il maggior numero di discorsi, senza fare preprocessing. Questo serve per poter creare il modello word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cognomi_analisi_long = {}\n",
    "for l in cognomi_analisi.keys():\n",
    "    cognomi_analisi_long[l] = [cognomi_analisi[l][i] for i in range(0,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': ['GRONCHI', 'MARTINO'],\n",
       " 'XII': ['LUCIANO VIOLANTE', 'LORENZO ACQUARONE'],\n",
       " 'XVII': ['ROBERTO GIACHETTI', 'SIMONE BALDELLI'],\n",
       " 'XVIII': ['ETTORE ROSATO', 'FABIO RAMPELLI']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognomi_analisi_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rimuovo i discorsi composti da meno di 10 parole\n",
    "discorsi_ridotti_long = {}\n",
    "\n",
    "for l in cognomi_analisi_long.keys():\n",
    "    for cog in cognomi_analisi_long[l]:\n",
    "           discorsi_ridotti_long[cog] = [d for d in legis[l][cog] if len(d)>10] #uso i discorsi originali, non quelli preprocessati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metto solo il lower case e rimuovo nomi partiti a inizio frase\n",
    "separator = ' '\n",
    "cont = 0\n",
    "\n",
    "for cog in discorsi_ridotti_long.keys():\n",
    "    if discorsi_ridotti_long[cog]!= []:\n",
    "            cont = 0\n",
    "            for l in discorsi_ridotti_long[cog]:\n",
    "                if l!= [] and l[0][0] == '(' and len(l[0])<15: #rimuovo i nomi dei partiti prima degli interventi\n",
    "                        pprint(l[0])\n",
    "                        discorsi_ridotti_long[cog][cont].remove(l[0])\n",
    "\n",
    "                disc = discorsi_ridotti_long[cog][cont]         \n",
    "                disc = separator.join(disc).lower()\n",
    "                reg = re.sub(\"[^A-Za-z']+\", ' ', disc)\n",
    "                final = reg.split(' ')\n",
    "                discorsi_ridotti_long[cog][cont] = final\n",
    "                cont = cont+1\n",
    "    print(cog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11099\n",
      "3294\n",
      "4412\n",
      "2445\n",
      "11659\n",
      "8014\n",
      "3466\n",
      "3319\n"
     ]
    }
   ],
   "source": [
    "for cog in discorsi_ridotti_long.keys():\n",
    "    print(len(discorsi_ridotti_long[cog]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(discorsi_ridotti_long, open(\"Discorsi_analisi/discorsi_analisi_long.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvataggio discorsi per Bigram e Trigram ###\n",
    "Mi servono i discorsi per analisi bigram e trigram, dove non vengano rimosse le stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "discorsi_analisi_ngram = {}\n",
    "\n",
    "for l in legis.keys():\n",
    "    for cog in cognomi_analisi[l]:\n",
    "        discorsi_analisi_ngram[cog] = legis[l][cog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GRONCHI', 16892),\n",
       " ('MARTINO', 4668),\n",
       " ('LEONE', 3917),\n",
       " ('MORO', 1648),\n",
       " ('SEGNI', 1331),\n",
       " ('LUCIANO VIOLANTE', 5907),\n",
       " ('LORENZO ACQUARONE', 3274),\n",
       " ('RAFFAELE DELLA \\\\ALLE', 3243),\n",
       " ('IRENE PIVETTI', 3141),\n",
       " ('IGNAZIO LA RUSSA', 2483),\n",
       " ('ROBERTO GIACHETTI', 15421),\n",
       " ('SIMONE BALDELLI', 10412),\n",
       " ('MARINA SERENI', 11318),\n",
       " ('LUIGI DI MAIO', 9666),\n",
       " ('LAURA BOLDRINI', 12302),\n",
       " ('ETTORE ROSATO', 4667),\n",
       " ('FABIO RAMPELLI', 4157),\n",
       " ('MARIA ROSARIA CARFAGNA', 3860),\n",
       " ('ROBERTO FICO', 5296),\n",
       " ('MARIA EDERA SPADONI', 3240)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(cog,len(discorsi_analisi_ngram[cog])) for cog in discorsi_analisi_ngram.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', \"'ordine\", 'del', 'giorno', 'reca', 'la', 'deliberazione', 'ai', 'sensi', 'dell', \"'articolo\", '96', '-bis,', 'comma', '3', 'del', 'regolamento', 'sul', 'disegno', 'di', 'legge', 'Conversione', 'in', 'legge', 'del', 'decreto', '-leg-ge', '29', 'aprile', '1994', 'n', '262', 'recante', 'provvedi', '-menti', 'finalizzati', 'alla', 'razionalizzazione', 'del', \"-l'indebitamento\", 'delle', 'società', 'per', 'azioni', 'interamente', 'possedute', 'dallo', 'Stato', 'Ricordo', 'che', 'nella', 'seduta', 'del', '31', 'maggio', 'scorso', 'la', 'I', 'Commissione', '(Affari', 'costituzio', '-nali)', 'ha', 'espresso', 'parere', 'contrario', 'sull', \"'esi-stenza\", 'dei', 'presupposti', 'richiesti', 'dal', 'secondo', 'comma', 'dell', \"'articolo\", '77', 'della', 'Costituzione', 'per', 'l', \"'adozione\", 'del', 'decreto', '-legge', 'n', '262', 'del', '1994', 'di', 'cui', 'al', 'disegno', 'di', 'legge', 'di', 'conversio', '-ne', 'n', '401', 'Ha', 'facoltà', 'di', 'parlare', 'il', 'presidente', 'della', 'Commissione', 'il', 'deputato', 'Selva']\n"
     ]
    }
   ],
   "source": [
    "print(discorsi_analisi_ngram['IRENE PIVETTI'][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = ' '\n",
    "cont = 0\n",
    "\n",
    "for cog in discorsi_analisi_ngram.keys():\n",
    "    if discorsi_analisi_ngram[cog]!= []: \n",
    "            cont = 0\n",
    "            for l in discorsi_analisi_ngram[cog]:\n",
    "                if l!= [] and l[0][0] == '(' and len(l[0])<15: #rimuovo i nomi dei partiti prima degli interventi\n",
    "                        pprint(l[0])\n",
    "                        discorsi_analisi_ngram[cog][cont].remove(l[0])\n",
    "\n",
    "                disc = discorsi_analisi_ngram[cog][cont]         \n",
    "                disc = separator.join(disc).lower()\n",
    "                reg = re.sub(\"[^A-Za-z']+\", ' ', disc)\n",
    "                final = reg.split(' ')\n",
    "                discorsi_analisi_ngram[cog][cont] = final\n",
    "                cont = cont+1\n",
    "    print(cog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(discorsi_analisi, open(\"Discorsi_analisi/discorsi_ngram.p\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
